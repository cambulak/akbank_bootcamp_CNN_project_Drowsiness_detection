{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1941284,"sourceType":"datasetVersion","datasetId":1157257}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sedatakda/akbank-bootcamp-project-cnn-drowsiness-detection?scriptVersionId=263287611\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Drowsiness Detection with CNN (Akbank Deep Learning Bootcamp Project)\n\n📖 Projenin Amacı\nBu projenin amacı, **MRL Eye Dataset** kullanılarak sürücülerde uykululuk (drowsiness) tespiti yapmaktır.  \nGözlerin açık (1) veya kapalı (0) olması CNN tabanlı derin öğrenme modelleri ile sınıflandırılmıştır.  \nProje, sürücü güvenliği uygulamalarına temel teşkil edebilecek bir \"driver monitoring\" sistemi geliştirmeyi hedeflemektedir.\n\n📊 Veri Seti\n- **Dataset:** /kaggle/input/drowsiness-detection \n- **Toplam Görüntü:** 84,898  \n- **Etiket:** `eye_state` (0 = closed, 1 = open)  \n- **Ek Bilgiler:** gender, glasses, reflections, lighting, sensor ID  \n\nVeri ön işleme adımları:  \n- Görseller 64x64 (CNN) ve 96x96 (Transfer Learning) boyutuna getirildi.  \n- Normalize edildi (0–1 aralığı).  \n- Train/Validation/Test setlerine ayrıldı.  \n- Data augmentation uygulandı: rotation, flip, zoom, brightness.  \n\nKullanılan Yöntemler\n- **Baseline CNN Modeli** (Conv2D, MaxPooling, Dense, Dropout, ReLU, Sigmoid)  \n- **Transfer Learning (MobileNetV2, ImageNet ağırlıkları)**  \n- **Hiperparametre Optimizasyonu:**  \n  - Katman sayısı  \n  - Filtre sayısı (32/64)  \n  - Dropout oranı (0.3/0.5)  \n  - Dense layer units (128/256)  \n  - Learning rate (0.001, 0.0001)  \n  - Batch size (32/64)  \n  - Optimizer seçimi (Adam, SGD)  \n\n","metadata":{}},{"cell_type":"markdown","source":"# 1. KÜTÜPHANELERİN YÜKLENMESİ\n\n","metadata":{}},{"cell_type":"code","source":"\n# Temel\nimport os\nimport datetime\nimport cv2\nimport numpy as np\nimport pandas as pd\n\n# Görselleştirme\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Modelleme (TensorFlow / Keras)\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\n\n# Değerlendirme\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:47:41.382181Z","iopub.execute_input":"2025-09-22T07:47:41.382686Z","iopub.status.idle":"2025-09-22T07:47:41.812752Z","shell.execute_reply.started":"2025-09-22T07:47:41.382661Z","shell.execute_reply":"2025-09-22T07:47:41.811961Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. VERİ ÖN İŞLEME ve GÖRSELLEŞTİRME\n\n## a. Veri Önişleme ve Keşifsel Analiz\n\n- Görseller normalize edilmiştir.\n- Train/Validation/Test ayrımı yapılmıştır.\n- Data Augmentation (rotation, flip, zoom, color jitter vb.) ile veri çeşitliliği artırılmıştır.\n\nAşağıda örnek görsellerden bazıları yer almaktadır:\n","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\n\n# Dataset klasör yolu (Kaggle'a eklediğinde ../input/ klasörü içinde olacak)\nDATA_DIR = \"/kaggle/input/drowsiness-detection\"\n\nimages = []\nlabels = []\n\n# Dataset yapısı: her dosya adında etiket bilgisi var\n# Örnek: s0028_00001_0_0_0_0_0_01.png\n# Format: subjectID imageID gender glasses eye_state reflections lighting sensorID\n\nfor folder in os.listdir(DATA_DIR):\n    folder_path = os.path.join(DATA_DIR, folder)\n    if os.path.isdir(folder_path):\n        for file in os.listdir(folder_path):\n            if file.endswith(\".png\"):\n                file_path = os.path.join(folder_path, file)\n\n                # Dosya adından label çekme\n                parts = file.split('_')\n                eye_state = int(parts[4])  # 0=kapalı, 1=açık\n\n                # Görüntüyü okuma (gri tonlama, boyutlama)\n                img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n                img = cv2.resize(img, (64,64))\n\n                images.append(img)\n                labels.append(eye_state)\n\nimages = np.array(images) / 255.0  # normalizasyon\nlabels = np.array(labels)\n\nprint(\"Toplam görüntü:\", images.shape)\nprint(\"Etiket dağılımı:\", np.bincount(labels))\n\n# Görselleri 4D hale getirme (CNN için)\nimages = images.reshape(-1, 64, 64, 1)\n\n# Train - Test ayırma (%70 - %15 - %15)\nX_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, stratify=labels, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n\nprint(\"Train set:\", X_train.shape, len(y_train))\nprint(\"Validation set:\", X_val.shape, len(y_val))\nprint(\"Test set:\", X_test.shape, len(y_test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:47:45.043487Z","iopub.execute_input":"2025-09-22T07:47:45.044505Z","iopub.status.idle":"2025-09-22T07:54:42.82386Z","shell.execute_reply.started":"2025-09-22T07:47:45.044479Z","shell.execute_reply":"2025-09-22T07:54:42.822944Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Etiket dağılımı\nsns.countplot(x=labels)\nplt.title(\"Eye State Dağılımı (0=Kapalı, 1=Açık)\")\nplt.show()\n\n# Örnek görseller\nfig, axes = plt.subplots(1,5, figsize=(15,5))\nfor i, ax in enumerate(axes):\n    ax.imshow(X_train[i].reshape(64,64), cmap='gray')\n    ax.set_title(f\"Label: {y_train[i]}\")\n    ax.axis(\"off\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:54:48.257183Z","iopub.execute_input":"2025-09-22T07:54:48.25747Z","iopub.status.idle":"2025-09-22T07:54:48.732704Z","shell.execute_reply.started":"2025-09-22T07:54:48.257449Z","shell.execute_reply":"2025-09-22T07:54:48.731946Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## b. Data Augmentation","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\nval_datagen = ImageDataGenerator()\ntest_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=32)\nval_generator = val_datagen.flow(X_val, y_val, batch_size=32)\ntest_generator = test_datagen.flow(X_test, y_test, batch_size=32, shuffle=False)\n\n# Augmentation örneği\nsample_img = X_train[0].reshape((1,64,64,1))\naug_iter = train_datagen.flow(sample_img, batch_size=1)\n\nfig, axes = plt.subplots(1,5, figsize=(15,5))\nfor i in range(5):\n    batch = next(aug_iter)\n    axes[i].imshow(batch[0].reshape(64,64), cmap='gray')\n    axes[i].axis(\"off\")\nplt.suptitle(\"Augmentation Örnekleri\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:54:51.881633Z","iopub.execute_input":"2025-09-22T07:54:51.882258Z","iopub.status.idle":"2025-09-22T07:54:52.297833Z","shell.execute_reply.started":"2025-09-22T07:54:51.882235Z","shell.execute_reply":"2025-09-22T07:54:52.297143Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. MODELİN EĞİTİLMESİ\n\n## a. Model Mimarisi\n\n### CNN Modeli\n- Convolutional Layers\n- Pooling Layers\n- Dropout\n- Dense Layers\n- Aktivasyon: ReLU, Sigmoid\n\n### Transfer Learning (Bonus)\n- Pre-trained model kullanılarak (ör. MobileNet, EfficientNet) performans artırılmıştır.\n\nModel özet çıktısı aşağıdadır:\n","metadata":{}},{"cell_type":"code","source":"# =======================================================\n# 3. CNN MODELİNİN OLUŞTURULMASI\n# =======================================================\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\nmodel = Sequential([\n    # 1. Convolutional Katman\n    Conv2D(32, (3,3), activation='relu', input_shape=(64,64,1)),\n    MaxPooling2D(2,2),\n    \n    # 2. Convolutional Katman\n    Conv2D(64, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n    \n    # 3. Convolutional Katman\n    Conv2D(128, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n    \n    # Flatten + Dense Katmanlar\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')  # Binary output\n])\n\n# Model derleme\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:54:57.738336Z","iopub.execute_input":"2025-09-22T07:54:57.739016Z","iopub.status.idle":"2025-09-22T07:54:59.236033Z","shell.execute_reply.started":"2025-09-22T07:54:57.738993Z","shell.execute_reply":"2025-09-22T07:54:59.235314Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## b. Eğitim Süreci\n\nAşağıda eğitim ve doğrulama seti için **accuracy** ve **loss** grafiklerinin değişimi yer almaktadır.  \nBu grafikler overfitting/underfitting durumlarını yorumlamamıza yardımcı olur:\n","metadata":{}},{"cell_type":"code","source":"# =======================================================\n# 3.1 MODELİN EĞİTİMİ\n# =======================================================\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=15,\n    verbose=1\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:55:02.82772Z","iopub.execute_input":"2025-09-22T07:55:02.828245Z","iopub.status.idle":"2025-09-22T07:59:33.380106Z","shell.execute_reply.started":"2025-09-22T07:55:02.828204Z","shell.execute_reply":"2025-09-22T07:59:33.379473Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Accuracy grafiği\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title(\"Model Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()\n\n# Loss grafiği\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title(\"Model Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:59:37.331646Z","iopub.execute_input":"2025-09-22T07:59:37.331961Z","iopub.status.idle":"2025-09-22T07:59:37.647878Z","shell.execute_reply.started":"2025-09-22T07:59:37.331938Z","shell.execute_reply":"2025-09-22T07:59:37.647193Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. MODEL DEĞERLENDİRMESİ\n\nAşağıda **Confusion Matrix** ve **Classification Report** verilmiştir:\n\n- Accuracy: %98\n- Precision / Recall / F1-score değerleri her iki sınıfta da dengeli ve yüksektir.\n- Model, drowsiness detection için endüstriyel seviyede başarı göstermektedir.\n","metadata":{}},{"cell_type":"markdown","source":"## a. Hiperparametre Optimizasyonu\n\nKeras Tuner kullanılarak aşağıdaki parametreler üzerinde denemeler yapılmıştır:\n\n- Filtre sayısı\n- Kernel boyutu\n- Dense layer boyutları\n- Dropout oranı\n- Learning Rate\n\n**En iyi sonuç veren kombinasyon:**\n- Kernel Size: 5\n- Filters: 64\n- Dense Units: 64\n- Dropout: 0.5\n- Learning Rate: 0.001\n- Val Accuracy: **%96.55**\n","metadata":{}},{"cell_type":"code","source":"def create_model(filters=32, dropout=0.5, dense_units=128, lr=0.001):\n    model = Sequential([\n        Conv2D(filters, (3,3), activation='relu', input_shape=(64,64,1)),\n        MaxPooling2D(2,2),\n        Conv2D(filters*2, (3,3), activation='relu'),\n        MaxPooling2D(2,2),\n        Flatten(),\n        Dense(dense_units, activation='relu'),\n        Dropout(dropout),\n        Dense(1, activation='sigmoid')\n    ])\n    \n    optimizer = Adam(learning_rate=lr)\n    model.compile(optimizer=optimizer,\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n# Örnek deneme\nmodel_test = create_model(filters=64, dropout=0.3, dense_units=256, lr=0.0005)\nhistory_test = model_test.fit(train_generator, validation_data=val_generator, epochs=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:59:43.308536Z","iopub.execute_input":"2025-09-22T07:59:43.30882Z","iopub.status.idle":"2025-09-22T08:02:41.381851Z","shell.execute_reply.started":"2025-09-22T07:59:43.308801Z","shell.execute_reply":"2025-09-22T08:02:41.381246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import keras_tuner as kt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# Modeli tanımlıyoruz\ndef build_model(hp):\n    model = Sequential()\n    \n    # İlk Conv katmanı\n    kernel_size = hp.Choice(\"kernel_size\", [3, 5])  # int seçtir\n    model.add(Conv2D(\n        filters=hp.Choice(\"filters\", [32, 64, 128]),\n        kernel_size=(kernel_size, kernel_size),  # tuple'a çeviriyoruz\n        activation='relu',\n        input_shape=(64,64,1)   # senin veri boyutuna göre (64,64,1) veya (96,96,3) olabilir\n    ))\n    \n    model.add(MaxPooling2D(2,2))\n    model.add(Flatten())\n    \n    # Dense katmanı\n    model.add(Dense(\n        units=hp.Choice(\"dense_units\", [64, 128, 256]),\n        activation='relu'\n    ))\n    \n    # Dropout\n    model.add(Dropout(hp.Choice(\"dropout\", [0.3, 0.5, 0.7])))\n    \n    # Çıkış katmanı\n    model.add(Dense(1, activation='sigmoid'))\n\n    # Derleme\n    model.compile(\n        optimizer=Adam(learning_rate=hp.Choice(\"lr\", [1e-2, 1e-3, 1e-4])),\n        loss=\"binary_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    return model\n\n\n# Tuner tanımlıyoruz\ntuner = kt.RandomSearch(\n    build_model,\n    objective=\"val_accuracy\",\n    max_trials=5,         # denenecek farklı model sayısı\n    executions_per_trial=1,\n    directory=\"my_tuner\",\n    project_name=\"drowsiness_detection\"\n)\n\n# Aramayı başlatıyoruz\ntuner.search(\n    train_generator,\n    validation_data=val_generator,\n    epochs=5\n)\n\n# En iyi modeli seçelim\nbest_model = tuner.get_best_models(num_models=1)[0]\n\n# Sonuçları özetleyelim\ntuner.results_summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:03:14.894119Z","iopub.execute_input":"2025-09-22T08:03:14.894453Z","iopub.status.idle":"2025-09-22T08:10:37.631267Z","shell.execute_reply.started":"2025-09-22T08:03:14.894425Z","shell.execute_reply":"2025-09-22T08:10:37.630611Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model = tuner.get_best_models(num_models=1)[0]\n\nhistory_best = best_model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=15,   # 15–20 arası iyi olabilir\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:14:13.127591Z","iopub.execute_input":"2025-09-22T08:14:13.127935Z","iopub.status.idle":"2025-09-22T08:18:31.583496Z","shell.execute_reply.started":"2025-09-22T08:14:13.127912Z","shell.execute_reply":"2025-09-22T08:18:31.582937Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history_best.history['accuracy'], label='Train Acc')\nplt.plot(history_best.history['val_accuracy'], label='Val Acc')\nplt.title(\"Accuracy Grafiği\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()\n\nplt.plot(history_best.history['loss'], label='Train Loss')\nplt.plot(history_best.history['val_loss'], label='Val Loss')\nplt.title(\"Loss Grafiği\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:18:37.594029Z","iopub.execute_input":"2025-09-22T08:18:37.594337Z","iopub.status.idle":"2025-09-22T08:18:37.922507Z","shell.execute_reply.started":"2025-09-22T08:18:37.594314Z","shell.execute_reply":"2025-09-22T08:18:37.921839Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## b. Overfitting / Underfitting Kontrolü\n\nOverfitting → Train accuracy yüksek, val accuracy düşük → Dropout artır, LR düşürülür.\n\nUnderfitting → Hem train hem val düşük → daha fazla katman/filtre ekle, LR artırılır.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Tahminleri al\ny_pred = best_model.predict(test_generator)\ny_pred_classes = (y_pred > 0.5).astype(\"int32\")\n\n# Gerçek etiketleri al\ntry:\n    y_true = test_generator.classes   # flow_from_directory için\nexcept:\n    try:\n        y_true = test_generator.labels  # bazı versiyonlarda mevcut\n    except:\n        y_true = y_test                 # flow(X, y) verdiysen direk y_test kullan\n\n# Confusion Matrix\ncm = confusion_matrix(y_true, y_pred_classes)\n\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Closed\",\"Open\"], yticklabels=[\"Closed\",\"Open\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Classification Report\nprint(classification_report(y_true, y_pred_classes, target_names=[\"Closed\",\"Open\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:18:42.491191Z","iopub.execute_input":"2025-09-22T08:18:42.491447Z","iopub.status.idle":"2025-09-22T08:18:43.629457Z","shell.execute_reply.started":"2025-09-22T08:18:42.491431Z","shell.execute_reply":"2025-09-22T08:18:43.628872Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Modelin overfitting yapmamış, hem train hem validation/test skorları yüksek.\n\nPrecision ve recall değerleri çok dengeli, yani model hem yanlış alarm (false positive) hem de gözden kaçırma (false negative) oranlarını düşük tutuyor.\n\nDrowsiness detection için endüstriyel kullanım seviyesinde bir başarı yakalanmış.","metadata":{}},{"cell_type":"markdown","source":"Overfitting (aşırı öğrenme):\n\nTrain Accuracy → yükseliyor (%95+)\n\nVal Accuracy → düşük kalıyor (%80 civarı)\n\nTrain Loss düşerken Val Loss artmaya başlıyor\n\nUnderfitting (yetersiz öğrenme):\n\nHem Train hem Val Accuracy düşük (%60–70 civarı)\n\nTrain ve Val Loss yüksek kalıyor\n\nİdeal öğrenme:\n\nTrain ve Val Accuracy birlikte yükseliyor\n\nTrain ve Val Loss birlikte azalıyor\n\nAradaki fark az","metadata":{}},{"cell_type":"markdown","source":"# 5. GÖRSELLEŞTİRME\n## a. Tensorboard Entegrasyonu","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import TensorBoard\nimport datetime\n\n# logs/fit/yyyy-mm-dd-hhmm klasörüne kaydet\nlog_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n\nhistory = best_model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=10,\n    callbacks=[tensorboard]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:19:40.05067Z","iopub.execute_input":"2025-09-22T08:19:40.05132Z","iopub.status.idle":"2025-09-22T08:22:42.777471Z","shell.execute_reply.started":"2025-09-22T08:19:40.051295Z","shell.execute_reply":"2025-09-22T08:22:42.776367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%tensorboard --logdir logs/fit/20250922-081940/\n","metadata":{"execution":{"iopub.status.busy":"2025-09-22T08:29:47.103554Z","iopub.execute_input":"2025-09-22T08:29:47.104111Z","iopub.status.idle":"2025-09-22T08:29:53.120307Z","shell.execute_reply.started":"2025-09-22T08:29:47.104079Z","shell.execute_reply":"2025-09-22T08:29:53.119589Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!kill 2036\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:29:44.007887Z","iopub.execute_input":"2025-09-22T08:29:44.008174Z","iopub.status.idle":"2025-09-22T08:29:44.179661Z","shell.execute_reply.started":"2025-09-22T08:29:44.008155Z","shell.execute_reply":"2025-09-22T08:29:44.178614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ls logs/fit\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:28:32.572771Z","iopub.execute_input":"2025-09-22T08:28:32.57346Z","iopub.status.idle":"2025-09-22T08:28:32.751648Z","shell.execute_reply.started":"2025-09-22T08:28:32.57343Z","shell.execute_reply":"2025-09-22T08:28:32.750921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Accuracy\nplt.plot(history.history['accuracy'], label='train_acc')\nplt.plot(history.history['val_accuracy'], label='val_acc')\nplt.title(\"Accuracy\")\nplt.legend()\nplt.show()\n\n# Loss\nplt.plot(history.history['loss'], label='train_loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.title(\"Loss\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:31:28.863328Z","iopub.execute_input":"2025-09-22T08:31:28.863654Z","iopub.status.idle":"2025-09-22T08:31:29.143702Z","shell.execute_reply.started":"2025-09-22T08:31:28.863631Z","shell.execute_reply":"2025-09-22T08:31:29.142923Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. İLAVELER\n## a. 3 Kombinasyonluk Hiperparametre Denemesi\n\ndropout, filtre sayısı ve learning rate değişimlerinin performansa etkisini gözlemleyebileceğiz","metadata":{}},{"cell_type":"code","source":"# Fonksiyon: Model oluşturma\ndef create_model(filters=32, dropout=0.5, dense_units=128, lr=0.001):\n    model = Sequential([\n        Conv2D(filters, (3,3), activation='relu', input_shape=(64,64,1)),\n        MaxPooling2D(2,2),\n        Conv2D(filters*2, (3,3), activation='relu'),\n        MaxPooling2D(2,2),\n        Flatten(),\n        Dense(dense_units, activation='relu'),\n        Dropout(dropout),\n        Dense(1, activation='sigmoid')\n    ])\n    \n    optimizer = Adam(learning_rate=lr)\n    model.compile(optimizer=optimizer,\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n# Deneme kombinasyonları\nexperiments = [\n    {\"filters\": 32, \"dropout\": 0.3, \"dense_units\": 128, \"lr\": 0.001},\n    {\"filters\": 64, \"dropout\": 0.5, \"dense_units\": 256, \"lr\": 0.0005},\n    {\"filters\": 64, \"dropout\": 0.3, \"dense_units\": 128, \"lr\": 0.0001},\n]\n\nhistories = []\nresults = []\n\nfor i, params in enumerate(experiments, 1):\n    print(f\"\\n🔹 Deneme {i}: {params}\")\n    model = create_model(**params)\n    history = model.fit(\n        train_generator,\n        validation_data=val_generator,\n        epochs=5,  # hızlı deneme için 5 epoch\n        verbose=1\n    )\n    histories.append(history)\n    \n    # Son epoch accuracy sonuçları\n    train_acc = history.history['accuracy'][-1]\n    val_acc = history.history['val_accuracy'][-1]\n    results.append((params, train_acc, val_acc))\n\n# Sonuçları tablo gibi yazdır\nprint(\"\\n📊 Deneme Sonuçları:\")\nfor i, (params, train_acc, val_acc) in enumerate(results, 1):\n    print(f\"Deneme {i}: {params} -> Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:31:58.906707Z","iopub.execute_input":"2025-09-22T08:31:58.907573Z","iopub.status.idle":"2025-09-22T08:36:25.499357Z","shell.execute_reply.started":"2025-09-22T08:31:58.907538Z","shell.execute_reply":"2025-09-22T08:36:25.49852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Accuracy grafikleri\nplt.figure(figsize=(10,6))\nfor i, history in enumerate(histories, 1):\n    plt.plot(history.history['val_accuracy'], label=f\"Deneme {i} Val Acc\")\nplt.title(\"Validation Accuracy Karşılaştırması\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()\n\n# Loss grafikleri\nplt.figure(figsize=(10,6))\nfor i, history in enumerate(histories, 1):\n    plt.plot(history.history['val_loss'], label=f\"Deneme {i} Val Loss\")\nplt.title(\"Validation Loss Karşılaştırması\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:36:31.071185Z","iopub.execute_input":"2025-09-22T08:36:31.071755Z","iopub.status.idle":"2025-09-22T08:36:31.436476Z","shell.execute_reply.started":"2025-09-22T08:36:31.071731Z","shell.execute_reply":"2025-09-22T08:36:31.435783Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Deneme 1: Basit model, düşük dropout → genelde daha hızlı öğrenir ama overfit olabilir.\n\nDeneme 2: Daha fazla filtre + yüksek dropout → daha güçlü model ama daha uzun eğitim.\n\nDeneme 3: Çok düşük learning rate → yavaş öğrenme, ama daha stabil.","metadata":{}},{"cell_type":"markdown","source":"## b. Transfer Learning","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\n\n# Giriş boyutu (bizim dataset 64x64, ama MobileNetV2 en az 96x96 istiyor)\ninput_shape = (64, 64, 3)  \n\n# Base model (önceden eğitilmiş, üst katmanlar çıkarıldı)\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n\n# Base modelin ağırlıklarını dondur (ilk aşamada fine-tune yapmıyoruz)\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Yeni katmanlar ekleme\nx = base_model.output\nx = GlobalAveragePooling2D()(x)      # Flatten yerine GAP\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.5)(x)\noutput = Dense(1, activation='sigmoid')(x)  # Binary output\n\n# Model oluşturma\nmodel_tl = Model(inputs=base_model.input, outputs=output)\n\n# Derleme\nmodel_tl.compile(optimizer='adam',\n                 loss='binary_crossentropy',\n                 metrics=['accuracy'])\n\nmodel_tl.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:36:35.293204Z","iopub.execute_input":"2025-09-22T08:36:35.293476Z","iopub.status.idle":"2025-09-22T08:36:36.424349Z","shell.execute_reply.started":"2025-09-22T08:36:35.293457Z","shell.execute_reply":"2025-09-22T08:36:36.423696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Gri resimleri RGB'ye dönüştür\nX_train_rgb = np.repeat(X_train, 3, axis=-1)\nX_val_rgb = np.repeat(X_val, 3, axis=-1)\nX_test_rgb = np.repeat(X_test, 3, axis=-1)\n\n# Data augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\nval_datagen = ImageDataGenerator()\ntest_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow(X_train_rgb, y_train, batch_size=32)\nval_generator = val_datagen.flow(X_val_rgb, y_val, batch_size=32)\ntest_generator = test_datagen.flow(X_test_rgb, y_test, batch_size=32, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:36:43.612753Z","iopub.execute_input":"2025-09-22T08:36:43.613526Z","iopub.status.idle":"2025-09-22T08:36:46.076537Z","shell.execute_reply.started":"2025-09-22T08:36:43.613499Z","shell.execute_reply":"2025-09-22T08:36:46.075927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_tl = model_tl.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=10,\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:36:48.814585Z","iopub.execute_input":"2025-09-22T08:36:48.81509Z","iopub.status.idle":"2025-09-22T08:43:08.63366Z","shell.execute_reply.started":"2025-09-22T08:36:48.815064Z","shell.execute_reply":"2025-09-22T08:43:08.632857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Son 10 layer'ı listeleyelim\nfor layer in model_tl.layers[-10:]:\n    print(layer.name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:44:47.805783Z","iopub.execute_input":"2025-09-22T08:44:47.806494Z","iopub.status.idle":"2025-09-22T08:44:47.810955Z","shell.execute_reply.started":"2025-09-22T08:44:47.806467Z","shell.execute_reply":"2025-09-22T08:44:47.810115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport cv2\nfrom tensorflow.keras.models import Model\n\ndef get_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # Son convolution katmanını ve çıkışı elde etmek için model tanımla\n    grad_model = Model(\n        inputs=model.inputs,\n        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Gradient hesapla\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(predictions[0])\n        class_channel = predictions[:, pred_index]\n\n    # Gradients al\n    grads = tape.gradient(class_channel, conv_outputs)\n\n    # Ortalama gradientleri hesapla\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    conv_outputs = conv_outputs[0]\n\n    # Heatmap hesapla\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # Normalize et\n    heatmap = np.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:44:56.305968Z","iopub.execute_input":"2025-09-22T08:44:56.306257Z","iopub.status.idle":"2025-09-22T08:44:56.312016Z","shell.execute_reply.started":"2025-09-22T08:44:56.306238Z","shell.execute_reply":"2025-09-22T08:44:56.311192Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\n# Test setini 96x96 boyuta getir (MobileNetV2 için)\nX_test_resized = np.array([cv2.resize(img, (96,96)) for img in X_test_rgb])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:45:01.062879Z","iopub.execute_input":"2025-09-22T08:45:01.063185Z","iopub.status.idle":"2025-09-22T08:45:02.985785Z","shell.execute_reply.started":"2025-09-22T08:45:01.063163Z","shell.execute_reply":"2025-09-22T08:45:02.985191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Eğer X_test float64 ise uint8'e çevir\nX_test_uint8 = (X_test * 255).astype(\"uint8\") if X_test.max() <= 1.0 else X_test.astype(\"uint8\")\n\n# Gri → RGB dönüşümü\nX_test_rgb = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) for img in X_test_uint8])\n\n# 96x96 boyutuna resize et\nX_test_resized = np.array([cv2.resize(img, (96,96)) for img in X_test_rgb])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:45:06.223643Z","iopub.execute_input":"2025-09-22T08:45:06.22394Z","iopub.status.idle":"2025-09-22T08:45:06.842697Z","shell.execute_reply.started":"2025-09-22T08:45:06.223918Z","shell.execute_reply":"2025-09-22T08:45:06.842118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_tl.input_shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:45:09.639577Z","iopub.execute_input":"2025-09-22T08:45:09.639845Z","iopub.status.idle":"2025-09-22T08:45:09.644929Z","shell.execute_reply.started":"2025-09-22T08:45:09.639826Z","shell.execute_reply":"2025-09-22T08:45:09.644205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_resized = np.array([cv2.resize(img, (64,64)) for img in X_test_rgb])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:45:12.393435Z","iopub.execute_input":"2025-09-22T08:45:12.393707Z","iopub.status.idle":"2025-09-22T08:45:12.521541Z","shell.execute_reply.started":"2025-09-22T08:45:12.393688Z","shell.execute_reply":"2025-09-22T08:45:12.520731Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## c. Grad-CAM Görselleştirmesi\n\nModelin hangi bölgeleri dikkate aldığı, Grad-CAM tekniği ile görselleştirilmiştir.\nBu sayede gözün açık/kapalı olduğuna karar verirken modelin hangi piksellere odaklandığı analiz edilmiştir.\n\n","metadata":{}},{"cell_type":"code","source":"idx = 5\nimg = X_test_resized[idx]\nimg_input = np.expand_dims(img, axis=0)  # shape = (1, H, W, 3)\n\nlast_conv_layer_name = \"Conv_1\"  # MobileNetV2 için genelde bu\nheatmap = get_gradcam_heatmap(img_input, model_tl, last_conv_layer_name)\n\n# Görselleştirme\nplt.figure(figsize=(8,4))\nplt.subplot(1,2,1)\nplt.imshow(img.astype(\"uint8\"))\nplt.title(f\"True: {y_test[idx]}\")\n\nplt.subplot(1,2,2)\nplt.imshow(img.astype(\"uint8\"))\nplt.imshow(cv2.resize(heatmap, (img.shape[1], img.shape[0])), cmap='jet', alpha=0.5) \nplt.title(f\"Grad-CAM - {last_conv_layer_name}\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T08:45:18.149631Z","iopub.execute_input":"2025-09-22T08:45:18.149934Z","iopub.status.idle":"2025-09-22T08:45:19.212939Z","shell.execute_reply.started":"2025-09-22T08:45:18.149912Z","shell.execute_reply":"2025-09-22T08:45:19.212122Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. SONUÇLAR VE ÇIKARIMLAR\n\n- CNN tabanlı model + Transfer Learning ile **yüksek başarı** elde edilmiştir.\n- Data Augmentation, modelin genelleme kapasitesini artırmıştır.\n- Hiperparametre optimizasyonu (Keras Tuner) sayesinde %96.55 doğruluk sağlanmıştır.\n- Test setinde %98 başarı ile model oldukça güvenilirdir.\n\n","metadata":{}}]}